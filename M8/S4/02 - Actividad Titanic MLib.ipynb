{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a855fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear la SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"Titanic MLib Activity\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fbae0e",
   "metadata": {},
   "source": [
    "## 2. Carga del dataset Titanic\n",
    "\n",
    "En esta sección cargaremos el archivo `titanic.csv` ubicado en la carpeta de la sesión:\n",
    "\n",
    "- Ruta esperada (en este entorno): `M8/S4/titanic.csv`.\n",
    "- Asegúrese de que la ruta relativa sea correcta si mueve el notebook.\n",
    "\n",
    "También inspeccionaremos el esquema y algunas filas para entender la estructura de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bf7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cargar el archivo titanic.csv\n",
    "import os\n",
    "\n",
    "data_path = os.path.join(\"titanic.csv\")  # Ajustar si es necesario\n",
    "\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "print(f\"Número de filas: {df.count()}\")\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24203ebc",
   "metadata": {},
   "source": [
    "## 3. Análisis exploratorio básico\n",
    "\n",
    "Realice un análisis exploratorio para entender mejor los datos:\n",
    "- Distribución de la variable objetivo (por ejemplo, `Survived`).\n",
    "- Revisión de valores nulos.\n",
    "- Variables categóricas vs numéricas.\n",
    "\n",
    "A modo de ejemplo, a continuación se incluye un análisis mínimo. Puede ampliarlo según lo requiera el encargo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Distribución de la variable objetivo\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "target_col = 'Survived'  # Ajustar si el dataset usa otro nombre\n",
    "\n",
    "df.groupBy(target_col).count().orderBy(target_col).show()\n",
    "\n",
    "# 3.2 Conteo de valores nulos por columna\n",
    "null_counts = df.select([F.sum(F.col(c).isNull().cast('int')).alias(c) for c in df.columns])\n",
    "null_counts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb29f92",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento y construcción del Pipeline\n",
    "\n",
    "En esta sección construiremos un **Pipeline de Spark ML** que incluya:\n",
    "\n",
    "1. Transformadores de preprocesamiento:\n",
    "   - `StringIndexer` para variables categóricas.\n",
    "   - `OneHotEncoder` para generar variables dummy.\n",
    "   - `VectorAssembler` para combinar todas las features en un solo vector.\n",
    "2. Un estimador de clasificación (por ejemplo, `RandomForestClassifier`).\n",
    "3. Un proceso de validación y búsqueda de hiperparámetros (ParamGridBuilder + CrossValidator).\n",
    "\n",
    "Primero seleccionaremos las columnas que vamos a usar como features y definiremos cuáles son categóricas y cuáles numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Definir columnas de features y variable objetivo\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "label_col = 'Survived'  # variable objetivo\n",
    "\n",
    "# Ejemplo de selección de columnas (ajustar según el esquema real del CSV)\n",
    "numeric_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "categorical_cols = ['Sex', 'Embarked']\n",
    "\n",
    "# Indexación de la etiqueta (por si no está en formato numérico)\n",
    "label_indexer = StringIndexer(inputCol=label_col, outputCol='label', handleInvalid='keep')\n",
    "\n",
    "# Indexadores para variables categóricas\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=c, outputCol=f'{c}_idx', handleInvalid='keep')\n",
    "    for c in categorical_cols\n",
    "]\n",
    "\n",
    "# OneHotEncoder para variables categóricas indexadas\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[f'{c}_idx' for c in categorical_cols],\n",
    "    outputCols=[f'{c}_ohe' for c in categorical_cols],\n",
    ")\n",
    "\n",
    "# Columnas finales para el ensamblador\n",
    "assembler_inputs = numeric_cols + [f'{c}_ohe' for c in categorical_cols]\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol='features')\n",
    "\n",
    "assembler_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09bb76",
   "metadata": {},
   "source": [
    "## 4.2 Definir el estimador (modelo supervisado)\n",
    "\n",
    "En esta sección definimos un estimador de clasificación. Puedes cambiar el algoritmo\n",
    "(por ejemplo, `LogisticRegression`, `RandomForestClassifier`, `GBTClassifier`) según lo que\n",
    "quieras experimentar. En el ejemplo usaremos un **RandomForestClassifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Definir el estimador de clasificación\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol='label',\n",
    "    featuresCol='features',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfb0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Construir el Pipeline completo\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "stages = [label_indexer] + indexers + [encoder, assembler, rf]\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c73e91e",
   "metadata": {},
   "source": [
    "## 5. División de datos, validación cruzada y tuning\n",
    "\n",
    "En esta sección:\n",
    "\n",
    "- Dividiremos los datos en entrenamiento y prueba.\n",
    "- Definiremos una malla de hiperparámetros con `ParamGridBuilder`.\n",
    "- Configuraremos un `CrossValidator` para seleccionar el mejor modelo.\n",
    "- Entrenaremos el pipeline y evaluaremos el resultado en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129abdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Dividir datos en entrenamiento y prueba\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f'Train: {train_df.count()} filas, Test: {test_df.count()} filas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ec236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Definir la malla de hiperparámetros y el CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
    "\n",
    "param_grid = (ParamGridBuilder()\n",
    "    .addGrid(rf.numTrees, [50, 100])\n",
    "    .addGrid(rf.maxDepth, [5, 10])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fe33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Entrenar el modelo con validación cruzada\n",
    "cv_model = cv.fit(train_df)\n",
    "\n",
    "best_model = cv_model.bestModel  # PipelineModel\n",
    "best_rf = best_model.stages[-1]  # Última etapa: RandomForestClassificationModel\n",
    "\n",
    "print(best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db361172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Evaluar el mejor modelo en el conjunto de prueba\n",
    "pred_test = cv_model.transform(test_df)\n",
    "\n",
    "auc = evaluator.evaluate(pred_test)\n",
    "print(f'ROC AUC en test: {auc:.4f}')\n",
    "\n",
    "pred_test.select('Survived', 'prediction', 'probability').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b04df",
   "metadata": {},
   "source": [
    "## 6. Conclusiones\n",
    "\n",
    "En esta sección, redacte sus **conclusiones** respecto al modelo entrenado:\n",
    "\n",
    "- ¿Qué tan bien está rindiendo el modelo según las métricas obtenidas (por ejemplo, ROC AUC)?\n",
    "- ¿Qué posibles mejoras podría aplicar (más features, otros modelos, mejor manejo de nulos, etc.)?\n",
    "- ¿Qué limitaciones observa en el análisis realizado?\n",
    "\n",
    "Escriba sus conclusiones en esta celda en formato markdown."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
