{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Caso ECommerce SKLearn\n",
    "\n",
    "En este notebook, elaboraremos un modelo regresivo utilizando el enfoque de Aprendizaje de Máquina, utilizando la librería SKLearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports y Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Ecommerce.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Address</th>\n",
       "      <th>Avatar</th>\n",
       "      <th>Avg. Session Length</th>\n",
       "      <th>Time on App</th>\n",
       "      <th>Time on Website</th>\n",
       "      <th>Length of Membership</th>\n",
       "      <th>Yearly Amount Spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mstephenson@fernandez.com</td>\n",
       "      <td>835 Frank Tunnel\\nWrightmouth, MI 82180-9605</td>\n",
       "      <td>Violet</td>\n",
       "      <td>34.497268</td>\n",
       "      <td>12.655651</td>\n",
       "      <td>39.577668</td>\n",
       "      <td>4.082621</td>\n",
       "      <td>587.951054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hduke@hotmail.com</td>\n",
       "      <td>4547 Archer Common\\nDiazchester, CA 06566-8576</td>\n",
       "      <td>DarkGreen</td>\n",
       "      <td>31.926272</td>\n",
       "      <td>11.109461</td>\n",
       "      <td>37.268959</td>\n",
       "      <td>2.664034</td>\n",
       "      <td>392.204933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Email                                         Address  \\\n",
       "0  mstephenson@fernandez.com    835 Frank Tunnel\\nWrightmouth, MI 82180-9605   \n",
       "1          hduke@hotmail.com  4547 Archer Common\\nDiazchester, CA 06566-8576   \n",
       "\n",
       "      Avatar  Avg. Session Length  Time on App  Time on Website  \\\n",
       "0     Violet            34.497268    12.655651        39.577668   \n",
       "1  DarkGreen            31.926272    11.109461        37.268959   \n",
       "\n",
       "   Length of Membership  Yearly Amount Spent  \n",
       "0              4.082621           587.951054  \n",
       "1              2.664034           392.204933  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del modelo\n",
    "\n",
    "En el contexto del aprendizaje automático y la estadística, el término \"modelo\" se refiere a una representación matemática o computacional de un sistema, fenómeno o proceso que intenta capturar sus relaciones subyacentes. Un modelo se utiliza para hacer predicciones, explicar observaciones o comprender la estructura subyacente de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina las variables que corresponden a features (X) y a la variable objetivo (Y).\n",
    "X = df[['Avg. Session Length','Time on App','Time on Website','Length of Membership']]\n",
    "y = df['Yearly Amount Spent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifique los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Cruzada\n",
    "\n",
    "La validación cruzada es una técnica utilizada en el aprendizaje automático y la estadística, para evaluar el rendimiento de un modelo predictivo. Su objetivo principal es estimar la precisión de un modelo en datos no vistos. Esto se logra dividiendo el conjunto de datos en subconjuntos de entrenamiento y prueba de manera repetida y sistemática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos funcion que permite hacer una division de los datos de forma aleatoria (ejecute la instrucción)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función **train_test_split()** se utiliza para dividir un conjunto de datos en dos subconjuntos: uno para entrenamiento del modelo y otro para evaluar su rendimiento. La división se realiza de manera aleatoria, pero asegurando que los dos subconjuntos resultantes mantengan la misma proporción de clases o etiquetas si estamos trabajando con problemas de clasificación.\n",
    "\n",
    "Donde:\n",
    "\n",
    "- **X**: es la matriz de características o variables independientes.\n",
    "- **y**: es el vector de la variable objetivo o variable dependiente.\n",
    "- **test_size**: es el tamaño del conjunto de prueba en proporción al conjunto de datos total. Por ejemplo, si test_size=0.- 2, el 20% de los datos se utilizarán como conjunto de prueba y el 80% restante se utilizará como conjunto de entrenamiento.\n",
    "- **random_state**: es una semilla aleatoria que asegura que la división se realice de la misma manera en diferentes ejecuciones del código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividimos en train y test set (ejecute la instrucción)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de ejecutar **train_test_split()**, obtendrás cuatro conjuntos de datos:\n",
    "\n",
    "- **X_train**: matriz de características para entrenamiento.\n",
    "- **X_test**: matriz de características para pruebas.\n",
    "- **y_train**: vector de variable objetivo para entrenamiento.\n",
    "- **y_test**: vector de variable objetivo para pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprima las dimensiones de cada una de estas variables\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo\n",
    "\n",
    "Durante esta etapa, el modelo se ajusta a los datos de entrenamiento para minimizar una función de pérdida o error. El objetivo es encontrar los valores óptimos de los parámetros del modelo que minimicen la diferencia entre las predicciones del modelo y las etiquetas verdaderas en los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos la clase LinearRegression de la libreria sklearn (ejecute)\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creamos un objeto regresor lineal (ejecute)\n",
    "lm = LinearRegression()\n",
    "\n",
    "# entrenamos al modelo, con los datos de entrenamiento\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objeto **lm** es el **modelo entrenado**, y almacena atributos con la información de resultado del entrenamiento así como también métodos convenientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.5962591 , 38.78534598,  0.31038593, 61.89682859])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# este atributo permite ver los coeficientes resultantes del entrenamiento (ejecute)\n",
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1044.2574146365575"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# este atributo contiene el coeficiente del intercepto (ejecute)\n",
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones con el modelo entrenado\n",
    "\n",
    "El modelo entrenado permite que podamos realizar predicciones sobre datos nuevos. A continuación, vamos a crear una función que permita hacer predicciones a un set de datos X con el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cree una función que reciba una matriz X de features y retorne un vector y con las predicciones\n",
    "def predecir(X):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haga predicciones con su función y aplíquela al primer registro del set de datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma más sencilla, es utilizando el método **predict()**. El método **predict()** en el objeto **LinearRegression()** se utiliza para hacer predicciones basadas en un modelo de regresión lineal que ha sido entrenado previamente. En términos simples, una vez que has entrenado tu modelo de regresión lineal con datos conocidos, puedes usar el método predict() para predecir valores para nuevas entradas. Acá hay un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note que vamos a hacer predicciones sobre el set de test, \n",
    "# que es data nueva que no se utilizó durante el entrenamiento (ejecute)\n",
    "y_pred = lm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprima las primeras 5 predicciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del Modelo\n",
    "\n",
    "El módulo metrics de la biblioteca Scikit-learn (sklearn) proporciona una variedad de funciones para evaluar la calidad y el rendimiento de los modelos de aprendizaje automático. Estas métricas son herramientas importantes para comprender cómo se desempeña un modelo en la tarea para la que fue entrenado y para comparar diferentes modelos entre sí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos libreria de métricas (ejecute)\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La evaluación del modelo en el conjunto de datos no visto por el algoritmo, también conocido como conjunto de prueba (test set), es una parte esencial del proceso de evaluación del rendimiento de un modelo de aprendizaje automático. Cuando entrenamos un modelo de aprendizaje automático, utilizamos un conjunto de datos conocidos como conjunto de entrenamiento para ajustar los parámetros del modelo y hacerlo aprender patrones a partir de esos datos.\n",
    "\n",
    "Sin embargo, para determinar cómo se desempeñará el modelo en datos que no ha visto durante el entrenamiento, necesitamos evaluarlo en un conjunto de datos separado, llamado conjunto de prueba o test set. Este conjunto de prueba debe contener ejemplos que no hayan sido utilizados en el proceso de entrenamiento y que representen datos del mundo real que el modelo encontrará después de su despliegue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprima las métricas MAE, MSE y RMSE utilizando el módulo metrics\n",
    "# puede ver la documentación en el siguiente link: \n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "#\n",
    "print('MAE:',  metrics.??  )\n",
    "print('MSE:',  metrics.??  )\n",
    "print('RMSE:',  metrics.??  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score del Modelo\n",
    "\n",
    "En un modelo de regresión lineal, el \"score\" se refiere a la medida de rendimiento del modelo en el conjunto de datos de prueba. En Scikit-learn, la función **score()** para modelos de regresión lineal devuelve el coeficiente de determinación $R^{2}$ del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9843155370226726"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# el objeto modelo provee un método sencillo para obtener el score (ejecute)\n",
    "lm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-squared ajustado\n",
    "\n",
    "La librería SKLearn, que se especializa en machine learning, no cuenta con todas las métricas de estadística que aprendimos con la librería Statsmodels. Si deseamos utilizar el R cuadrado ajustado, entonces debemos calcularlo. La fórmula es la siguiente:\n",
    "\n",
    "$R^2_{adj} = 1 - (1-R^2)*\\frac{n-1}{n-p-1}$\n",
    "\n",
    "- n: cantidad de mediciones\n",
    "- p: cantidad de dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cree una función que permita realizar al cálculo del r-cuadrado-ajustado\n",
    "def r2adj():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿qué valor se obtiene?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de Features del Modelo\n",
    "\n",
    "La selección de características del modelo, también conocida como selección de variables o selección de atributos, es el proceso de elegir un subconjunto relevante de características (o variables independientes) para utilizar en la construcción del modelo de aprendizaje automático. El objetivo de la selección de características es mejorar el rendimiento del modelo al eliminar características irrelevantes, redundantes o que pueden estar causando sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el método estadístico, deberíamos aplicar métodos de selección basados en el valor-p, donde descartamos las variables que no tenemos certeza que influyan en la variable objetivo. Con el enfoque de aprendizaje de máquina, nos basta con descartar los coeficientes que tenga poca incidencia o que comparativamente son despreciables respecto a otros features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar variables comparando los coeficientes, es recomendable realizar un escalamiento de los datos. La razón principal para escalar los datos es asegurarse de que todas las características tengan un rango similar de valores. En particular:\n",
    "\n",
    "- Si algunas características tienen escalas mucho mayores que otras, pueden dominar la optimización del modelo, lo que significa que el modelo puede enfocarse excesivamente en esas características y pasar por alto otras características importantes.\n",
    "\n",
    "- Cuando se utilizan modelos lineales, como la regresión lineal, los coeficientes estimados representan la contribución de cada característica a la predicción. Escalar los datos asegura que los coeficientes sean comparables entre sí y facilita la interpretación de la importancia relativa de cada característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importe la siguiente librería que nos ayudará a realizar el escalamiento (ejecute)\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciamos objeto escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# le presentamos los datos para que calcule los parametros de escalamiento\n",
    "scaler.fit(X)\n",
    "\n",
    "# aplicamos la transformacion de escalamiento y creamos una nueva variable para almacenar el resultado\n",
    "X_sc = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# despliegue los primeros 5 registros de la matriz X_sc. ¿qué tipo de datos es?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reentrenamiento con datos escalados\n",
    "\n",
    "Vamos a repetir el proceso de entrenamiento, a objeto de ajustar los parámetros del modelo con los datos escalador. Recuerde que debemos aplicar validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividimos en train y test set (ejecute la instrucción)\n",
    "# note que ahora utilizamos X_sc\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sc, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ajustamos el modelo lineal con los datos escalados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrene el modelo nuevamente (complete)\n",
    "lm = LinearRegression()\n",
    "# complete...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Machine Learning, se emplean los siguientes términos:\n",
    "\n",
    "- A los **Predictores** se les llama **Features** (características)\n",
    "- A los **Coeficientes** se les llama **Pesos** (estandarizados)\n",
    "- Al **Intercepto** se le llama **Bias** (sesgo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprima los pesos de cada feature (ejecute)\n",
    "summary = pd.DataFrame(X.columns, columns=['Features'])\n",
    "summary['Weights'] = lm.coef_\n",
    "summary.append(['Intercept',lm.intercept_])\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En machine learning, no es tan relevante el valor de p para la selección del modelo, se compara el aporte de pesos para descartar un feature del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿qué variables seleccionaría? (comente)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizando una predicción con los features estandarizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debe ser un arreglo 2D (ejecute)\n",
    "p1 = [[34.497268,12.655651,39.577668,4.082621]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicamos el escalador (ejecute)\n",
    "p1_sc = scaler.transform(p1)\n",
    "p1_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizamos la predicción (ejecute)\n",
    "lm.predict(p1_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removiendo una variable del modelo\n",
    "\n",
    "Vamos a remover el feature que tiene menos peso en el modelo (Time on Website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Avg. Session Length','Time on App','Length of Membership']]\n",
    "y = df['Yearly Amount Spent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vuelva a repetir el proceso (escalamiento, validacion cruzada y entrenamiento)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciendo en Test set\n",
    "\n",
    "Con el modelo ajustado con 3 features, realice predicciones sobre el set de tests y evalúe el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete\n",
    "y_pred = ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ejecute)\n",
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecute\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecute\n",
    "metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuales\n",
    "\n",
    "También podemos realizar el análisis de residuales del modelo. Este análisis es importante porque podemos darnos cuenta que un modelo lineal puede ser demasiado simple para el problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot( y_test - y_pred )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
