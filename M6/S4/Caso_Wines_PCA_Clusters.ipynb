{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ecd54e",
   "metadata": {},
   "source": [
    "# Caso Wines – Análisis PCA y Clusterización\n",
    "\n",
    "Notebook reproducible para el caso *Wines*: análisis de componentes principales, selección de dimensiones, clusterización y comparación con segmentos reales de vinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Importar librerías necesarias\n",
    "# Comentario: en este bloque cargamos todas las librerías que usaremos\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e1d1e",
   "metadata": {},
   "source": [
    "## 1. Carga y preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad90c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1) Cargar datasets de características químicas y segmentos reales\n",
    "# Suponemos que el notebook está en la misma carpeta que wine-data.csv y wine-segments.csv\n",
    "\n",
    "data = pd.read_csv(\"wine-data.csv\")\n",
    "segments = pd.read_csv(\"wine-segments.csv\")\n",
    "\n",
    "# Renombrar columna de segmentos para mayor claridad\n",
    "segments.columns = [\"Cultivar\"]\n",
    "\n",
    "# Unir en un solo DataFrame por índice\n",
    "data_full = data.copy()\n",
    "data_full[\"Cultivar\"] = segments[\"Cultivar\"].values\n",
    "\n",
    "data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2) Revisión rápida de estructura y estadísticos básicos\n",
    "\n",
    "print(\"Dimensiones del dataset:\", data_full.shape)\n",
    "display(data_full.describe().T)\n",
    "\n",
    "data_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec0440",
   "metadata": {},
   "source": [
    "## 2. Análisis de Componentes Principales (PCA)\n",
    "\n",
    "En esta sección estandarizaremos las variables químicas, aplicaremos PCA y analizaremos la varianza explicada por cada componente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1) Separar variables explicativas (X) y variable de segmento (y)\n",
    "\n",
    "feature_cols = data.columns.tolist()  # todas las columnas de wine-data son numéricas\n",
    "X = data_full[feature_cols].values\n",
    "y = data_full[\"Cultivar\"].values\n",
    "\n",
    "X[:3], y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd77373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2) Estandarizar las variables\n",
    "# Comentario: PCA es sensible a la escala de las variables,\n",
    "# por lo que primero normalizamos a media 0 y varianza 1.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f37ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3) Ajustar PCA sin fijar número de componentes para ver toda la varianza\n",
    "\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_scaled)\n",
    "\n",
    "explained_var_ratio = pca_full.explained_variance_ratio_\n",
    "cum_explained_var = np.cumsum(explained_var_ratio)\n",
    "\n",
    "pca_var_df = pd.DataFrame({\n",
    "    \"Componente\": np.arange(1, len(explained_var_ratio) + 1),\n",
    "    \"Varianza_Explicada\": explained_var_ratio,\n",
    "    \"Varianza_Acumulada\": cum_explained_var\n",
    "})\n",
    "\n",
    "pca_var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b60ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4) Gráfico de la varianza explicada (scree plot) y varianza acumulada\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(pca_var_df[\"Componente\"], pca_var_df[\"Varianza_Explicada\"], marker=\"o\", label=\"Individual\")\n",
    "plt.plot(pca_var_df[\"Componente\"], pca_var_df[\"Varianza_Acumulada\"], marker=\"s\", label=\"Acumulada\")\n",
    "plt.xlabel(\"Componente principal\")\n",
    "plt.ylabel(\"Porcentaje de varianza explicada\")\n",
    "plt.title(\"Varianza explicada por componentes principales\")\n",
    "plt.xticks(pca_var_df[\"Componente\"])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af3f53",
   "metadata": {},
   "source": [
    "## 3. Selección de número de dimensiones\n",
    "\n",
    "En este paso decidimos cuántos componentes principales conservar en el nuevo espacio dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1) Ver la varianza acumulada para los primeros componentes\n",
    "\n",
    "pca_var_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5410fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2) Seleccionar la cantidad de dimensiones del nuevo espacio\n",
    "# Comentario:\n",
    "# - Para visualización bidimensional nos interesa usar 2 componentes.\n",
    "# - Estos suelen explicar una fracción importante de la varianza total.\n",
    "#   (ver tabla anterior de varianza acumulada).\n",
    "\n",
    "n_components_pca = 2\n",
    "print(f\"Número de componentes seleccionados para el nuevo espacio: {n_components_pca}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c334a124",
   "metadata": {},
   "source": [
    "## 4. Reducción al nuevo espacio dimensional y visualización\n",
    "\n",
    "Reducimos los datos al espacio de los primeros componentes principales seleccionados y graficamos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1) Aplicar PCA con el número de componentes seleccionado\n",
    "\n",
    "pca = PCA(n_components=n_components_pca)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "pca_cols = [f\"PC{i+1}\" for i in range(n_components_pca)]\n",
    "df_pca = pd.DataFrame(X_pca, columns=pca_cols)\n",
    "df_pca[\"Cultivar\"] = y\n",
    "\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468617ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2) Gráfico en el nuevo espacio PCA coloreado por Cultivar real\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    df_pca[\"PC1\"],\n",
    "    df_pca[\"PC2\"],\n",
    "    c=df_pca[\"Cultivar\"],\n",
    "    cmap=\"tab10\",\n",
    "    s=50,\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Vinos en espacio PCA (PC1 vs PC2) – coloreado por Cultivar real\")\n",
    "plt.legend(*scatter.legend_elements(), title=\"Cultivar\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b96793",
   "metadata": {},
   "source": [
    "> **Pregunta:** ¿Se aprecian clusters en el espacio de PC1 y PC2?\n",
    "\n",
    "A simple vista debieran observarse grupos parcialmente separados que corresponden aproximadamente a los 3 cultivares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc95fa1",
   "metadata": {},
   "source": [
    "## 5. Clusterización en el espacio PCA\n",
    "\n",
    "En esta sección aplicaremos un algoritmo de clusterización (K-Means) sobre los datos proyectados en el espacio PCA y seleccionaremos la cantidad de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1) Evaluar distintos valores de k con K-Means usando el espacio PCA\n",
    "# Comentario: usaremos tanto la inercia (método del codo) como el\n",
    "# coeficiente de silueta promedio para ayudar a elegir la cantidad de clusters.\n",
    "\n",
    "range_n_clusters = range(2, 8)  # probamos desde 2 hasta 7 clusters\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "\n",
    "for k in range_n_clusters:\n",
    "    kmeans_k = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_k = kmeans_k.fit_predict(df_pca[pca_cols])\n",
    "    inertias.append(kmeans_k.inertia_)\n",
    "    silhouettes.append(silhouette_score(df_pca[pca_cols], labels_k))\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"k\": list(range_n_clusters),\n",
    "    \"inertia\": inertias,\n",
    "    \"silhouette\": silhouettes\n",
    "})\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dafdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2) Graficar inercia (método del codo) y coeficiente de silueta\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(results_df[\"k\"], results_df[\"inertia\"], marker=\"o\")\n",
    "axes[0].set_title(\"Método del codo (inercia)\")\n",
    "axes[0].set_xlabel(\"Número de clusters (k)\")\n",
    "axes[0].set_ylabel(\"Inercia\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(results_df[\"k\"], results_df[\"silhouette\"], marker=\"o\", color=\"orange\")\n",
    "axes[1].set_title(\"Coeficiente de silueta promedio\")\n",
    "axes[1].set_xlabel(\"Número de clusters (k)\")\n",
    "axes[1].set_ylabel(\"Silueta\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for k, s in zip(results_df[\"k\"], results_df[\"silhouette\"]):\n",
    "    print(f\"k = {k}, silueta promedio = {s:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60729b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3) Seleccionar cantidad de clusters (k) basada en la silueta\n",
    "# Comentario: elegimos el k que maximiza el coeficiente de silueta.\n",
    "\n",
    "best_k = int(results_df.loc[results_df[\"silhouette\"].idxmax(), \"k\"])\n",
    "print(f\"Número de clusters seleccionado (según silueta): {best_k}\")\n",
    "\n",
    "# Ajustar K-Means final con best_k clusters en el espacio PCA\n",
    "kmeans_final = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "clusters_pca = kmeans_final.fit_predict(df_pca[pca_cols])\n",
    "\n",
    "# Guardar los labels de cluster\n",
    "df_pca[\"Cluster\"] = clusters_pca\n",
    "data_full[\"Cluster\"] = clusters_pca  # marcar dataset original con el número de cluster\n",
    "\n",
    "data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c84c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4) Visualizar los clusters encontrados en el espacio PCA\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    df_pca[\"PC1\"],\n",
    "    df_pca[\"PC2\"],\n",
    "    c=df_pca[\"Cluster\"],\n",
    "    cmap=\"tab10\",\n",
    "    s=50,\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(f\"Clusters de K-Means en espacio PCA (k = {best_k})\")\n",
    "plt.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c692bdb9",
   "metadata": {},
   "source": [
    "## 6. Comparación con segmentos reales y conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1) Comparar clusters encontrados vs. Cultivar real\n",
    "\n",
    "ct = pd.crosstab(data_full[\"Cultivar\"], data_full[\"Cluster\"], margins=True)\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862220c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2) (Opcional) Medir calidad de la clusterización con un índice externo\n",
    "\n",
    "ari = adjusted_rand_score(data_full[\"Cultivar\"], data_full[\"Cluster\"])\n",
    "print(f\"Índice de Rand Ajustado (ARI) entre clusters y cultivares reales: {ari:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a2ab2",
   "metadata": {},
   "source": [
    "### 6.3) Comentarios finales\n",
    "\n",
    "- El PCA nos permitió reducir la dimensionalidad del problema y visualizar las observaciones en 2 componentes principales, manteniendo gran parte de la varianza original.\n",
    "- Sobre este espacio reducido, K-Means encontró grupos basados en similitud de las características químicas de los vinos.\n",
    "- La comparación con los cultivares reales (tabla de contingencia y ARI) nos da una idea de qué tan bien la clusterización no supervisada recupera la estructura \"verdadera\" de las clases.\n",
    "- Un ARI cercano a 1 indica muy buen acuerdo; valores cercanos a 0 indican que los clusters no se parecen mucho a los cultivares reales.\n",
    "- En un contexto real, estos análisis ayudan a entender si la segmentación basada solo en características químicas es suficiente para distinguir tipos de vino o si se requieren más variables o modelos más sofisticados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0730826",
   "metadata": {},
   "source": [
    "### 6.4) Preguntas para resolver con este caso\n",
    "\n",
    "1. Usando la tabla `pca_var_df`, ¿cuánta varianza explica el **primer componente (PC1)**? Escribe el valor en porcentaje.  \n",
    "   *Tip:* Ejecuta la celda donde se muestra `pca_var_df` y toma el valor de la columna `Varianza_Explicada` para `Componente = 1` (primera fila). Luego multiplícalo por 100 para obtener el porcentaje.\n",
    "\n",
    "2. Según `pca_var_df`, ¿cuánta **varianza acumulada** explican **PC1 y PC2 juntos**? ¿Es más del 50%?  \n",
    "   *Tip:* En la misma tabla `pca_var_df`, mira la fila donde `Componente = 2` y toma el valor de la columna `Varianza_Acumulada`. Compáralo con 0.50 (50%).\n",
    "\n",
    "3. Mira el gráfico PC1 vs PC2 coloreado por `Cultivar`: ¿se distinguen **aproximadamente 3 grupos** o los puntos se ven muy mezclados? Describe brevemente lo que observas.  \n",
    "   *Tip:* Vuelve a ejecutar la celda del gráfico de PCA (PC1 vs PC2). Fíjate si los colores (cultivares) forman nubes separadas o si se superponen mucho.\n",
    "\n",
    "4. Observa la tabla de resultados de `results_df`: ¿para qué valor de **k** el coeficiente de **silueta** es mayor? Escribe ese valor de k.  \n",
    "   *Tip:* Ejecuta la celda que imprime `results_df` (o el bucle que muestra `k` y silueta). Busca la fila con el valor más alto en la columna `silhouette` y anota el `k` correspondiente.\n",
    "\n",
    "5. Con la tabla de contingencia entre `Cultivar` y `Cluster`, responde: ¿para qué **Cultivar** parece haber un cluster donde la mayoría de sus vinos caen en la misma columna (cluster)?  \n",
    "   *Tip:* Ejecuta la celda que calcula `ct = pd.crosstab(...)`. Para cada fila (Cultivar), identifica la columna (Cluster) con el número más alto. Esa combinación indica buena correspondencia.\n",
    "\n",
    "6. Mira el valor del Índice de Rand Ajustado (ARI) que se imprime: si está **cerca de 1**, ¿qué significa? ¿Y si estuviera **cerca de 0**? Explica en una o dos frases.  \n",
    "   *Tip:* Revisa la celda donde se imprime el `ari`. Piensa en “1” como *acuerdo perfecto* entre clusters y cultivares, y en “0” como *acuerdo similar al azar*.\n",
    "\n",
    "**Interpretación del ARI**  \n",
    "   - **ARI alto (cerca de 1)**: los clusters de K-Means se parecen mucho a los cultivares reales → **muy buena calidad** de clusterización.  \n",
    "   - **ARI medio**: hay cierta relación entre clusters y cultivares, pero con bastantes errores → **calidad moderada**.  \n",
    "   - **ARI bajo (cerca de 0)**: los clusters se parecen poco a los cultivares → la clusterización no está capturando bien la estructura real."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
